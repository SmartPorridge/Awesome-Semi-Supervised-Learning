# Awesome-Semi-Supervised-Learning

## Guide:

>* 1.Papers[]

>* 2.Paper Reading Notes

## 1.Papersï¼š

* Temporal ensembling for semi-supervised learning. Samuli Laine and Timo Aila. [paper_url](https://arxiv.org/abs/1610.02242)
  
* Mean teacher: Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. [paper_url](https://arxiv.org/abs/1703.01780)
  
* VAT: Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning. [paper_url](https://arxiv.org/abs/1704.03976)
  
* fast SWA: There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average. [paper_url](https://arxiv.org/abs/1806.05594)
  
* ICT by Bengio: Interpolation Consistency Training for Semi-Supervised Learning. [paper_url](https://arxiv.org/abs/1903.03825)
  
* MixMatch by Ian Goodfellow: Interpolation Consistency Training for Semi-Supervised Learning. [paper_url](https://arxiv.org/abs/1905.02249)
  

## 2.Paper Reading Notes
 
### Temporal ensembling for semi-supervised learning
to do

### Mean teacher: Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results.
to do

### VAT: Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning. 
to do

###  fast SWA: There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average.
to do

### ICT by Bengio: Interpolation Consistency Training for Semi-Supervised Learning.
to do

### MixMatch by Ian Goodfellow: Interpolation Consistency Training for Semi-Supervised Learning. 
to do


